# easyEval2 - 语义相似度评估系统 PRD

## 项目概述

**项目名称**: easyEval2  
**项目类型**: 语义相似度评估工具  
**目标项目**: EasyChat 对话系统  
**核心技术**: DeepSeek API + 语义相似度分析  
**项目定位**: 学习型评估项目，简单易用

---

## 项目背景

### 问题描述
- easyEval v1.0 使用关键词匹配方式评估对话完成率，存在局限性
- 无法准确评估语义层面的回答质量
- 需要更智能的评估方式来判断AI回答的相关性和准确性

### 解决方案
- 基于DeepSeek API构建语义相似度评估系统
- 通过AI模型判断问题与回答的语义匹配度
- 提供量化的评估分数和详细分析报告

---

## 项目目标

### 核心目标
1. **语义评估**: 实现基于AI的语义相似度评估
2. **量化分析**: 提供0-100分的评估分数
3. **简单易用**: 一键运行，自动化评估流程
4. **学习导向**: 代码结构清晰，便于学习和扩展

### 技术目标
- 集成DeepSeek API进行语义分析
- 设计专用的评估系统提示词
- 实现自动化的问答对评估
- 生成详细的评估报告

---

## 功能需求

### 核心功能

#### 1. 语义相似度评估
- **输入**: 问题文本 + AI回答文本
- **处理**: 通过DeepSeek API分析语义相关性
- **输出**: 相似度分数 (0-100) + 评估理由

#### 2. 批量评估处理
- 支持批量处理多个问答对
- 自动调用EasyChat获取回答
- 逐一进行语义相似度评估

#### 3. 评估报告生成
- 生成详细的评估报告
- 包含总体分数、单项分析、改进建议
- 支持JSON和文本格式输出

#### 4. 配置管理
- API密钥安全存储
- 评估参数可配置
- 系统提示词可自定义

### 辅助功能

#### 1. 错误处理
- API调用失败重试机制
- 网络异常处理
- 评估超时处理

#### 2. 日志记录
- 详细的评估过程日志
- API调用记录
- 错误信息记录

#### 3. 进度显示
- 实时评估进度条
- 当前处理状态显示
- 预估完成时间

---

## 技术架构

### 系统架构

```
easyEval2/
├── config/
│   ├── config.py          # 配置管理
│   └── prompts.py         # 系统提示词
├── src/
│   ├── semantic_eval.py   # 核心评估逻辑
│   ├── deepseek_client.py # DeepSeek API客户端
│   └── report_generator.py # 报告生成器
├── tests/
│   └── test_cases.json    # 测试用例
├── results/               # 评估结果
├── logs/                  # 日志文件
├── .env                   # API密钥配置
└── README.md              # 使用说明
```

### 核心模块

#### 1. DeepSeek API客户端
- 封装API调用逻辑
- 处理认证和请求
- 实现重试机制

#### 2. 语义评估引擎
- 构建评估提示词
- 调用DeepSeek API
- 解析评估结果

#### 3. EasyChat接口
- 自动调用EasyChat
- 获取AI回答
- 处理对话流程

#### 4. 报告生成器
- 汇总评估结果
- 生成统计分析
- 输出格式化报告

---

## 评估方法设计

### 语义相似度评估标准

#### 评分维度
1. **相关性** (30分): 回答是否与问题相关
2. **准确性** (25分): 回答内容是否准确
3. **完整性** (20分): 回答是否完整回应问题
4. **有用性** (15分): 回答是否对用户有帮助
5. **表达质量** (10分): 回答的语言表达质量

#### 评分标准
- **90-100分**: 优秀 - 完全符合预期
- **80-89分**: 良好 - 基本符合预期
- **70-79分**: 一般 - 部分符合预期
- **60-69分**: 较差 - 勉强相关
- **0-59分**: 很差 - 不相关或错误

### 系统提示词设计

```
你是一个专业的对话质量评估专家。请评估AI回答与用户问题的语义相似度和质量。

评估标准：
1. 相关性(30%): 回答是否直接回应了问题
2. 准确性(25%): 回答内容是否正确
3. 完整性(20%): 回答是否完整
4. 有用性(15%): 回答是否有实际帮助
5. 表达质量(10%): 语言是否清晰流畅

请给出0-100的分数，并简要说明评分理由。
```

---

## 数据流程

### 评估流程

1. **初始化**
   - 加载配置和API密钥
   - 初始化DeepSeek客户端
   - 准备测试用例

2. **获取回答**
   - 调用EasyChat API
   - 发送测试问题
   - 获取AI回答

3. **语义评估**
   - 构建评估提示词
   - 调用DeepSeek API
   - 解析评估结果

4. **结果处理**
   - 记录评估分数
   - 保存评估理由
   - 更新统计信息

5. **报告生成**
   - 汇总所有结果
   - 计算平均分数
   - 生成详细报告

### 数据格式

#### 测试用例格式
```json
{
  "id": "test_001",
  "question": "用户问题",
  "category": "问题分类",
  "expected_aspects": ["期望回答要点1", "期望回答要点2"],
  "priority": "high|medium|low"
}
```

#### 评估结果格式
```json
{
  "test_id": "test_001",
  "question": "用户问题",
  "answer": "AI回答",
  "semantic_score": 85,
  "evaluation_reason": "评估理由",
  "dimension_scores": {
    "relevance": 26,
    "accuracy": 22,
    "completeness": 18,
    "usefulness": 13,
    "expression": 8
  },
  "timestamp": "2024-01-15T10:30:00"
}
```

---

## 技术实现

### API集成

#### DeepSeek API配置
```python
# .env 文件
DEEPSEEK_API_KEY=your_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_MODEL=deepseek-chat
```

#### API调用示例
```python
import openai

client = openai.OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url=os.getenv("DEEPSEEK_BASE_URL")
)

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": evaluation_prompt},
        {"role": "user", "content": f"问题: {question}\n回答: {answer}"}
    ],
    temperature=0.1
)
```

### 核心算法

#### 语义评估算法
1. 构建包含问题和回答的评估提示
2. 调用DeepSeek API获取评估结果
3. 解析返回的分数和理由
4. 验证分数范围和格式
5. 记录评估结果

#### 批量处理算法
1. 遍历所有测试用例
2. 并发调用EasyChat获取回答
3. 顺序进行语义评估（避免API限流）
4. 实时更新进度和统计
5. 处理异常和重试

---

## 项目计划

### 开发阶段

#### 第一阶段：基础框架 (1-2天)
- [ ] 创建项目结构
- [ ] 配置DeepSeek API客户端
- [ ] 实现基础的语义评估功能
- [ ] 创建简单的测试用例

#### 第二阶段：核心功能 (2-3天)
- [ ] 完善评估算法
- [ ] 集成EasyChat调用
- [ ] 实现批量评估
- [ ] 添加进度显示

#### 第三阶段：报告和优化 (1-2天)
- [ ] 实现报告生成
- [ ] 添加错误处理
- [ ] 性能优化
- [ ] 完善文档

### 里程碑

1. **MVP版本**: 基础语义评估功能
2. **完整版本**: 批量评估和报告生成
3. **优化版本**: 性能优化和错误处理

---

## 风险评估

### 技术风险
- **API限流**: DeepSeek API可能有调用频率限制
- **成本控制**: API调用产生费用，需要控制测试规模
- **网络稳定性**: API调用依赖网络连接

### 解决方案
- 实现请求间隔控制
- 设置API调用预算限制
- 添加重试和降级机制

---

## 成功标准

### 功能标准
- [ ] 成功集成DeepSeek API
- [ ] 实现准确的语义相似度评估
- [ ] 生成详细的评估报告
- [ ] 支持批量自动化评估

### 性能标准
- 单次评估时间 < 10秒
- 批量评估支持20-50个测试用例
- API调用成功率 > 95%
- 评估结果一致性和可靠性

### 易用性标准
- 一键运行: `python src/semantic_eval.py`
- 清晰的配置说明
- 详细的使用文档
- 友好的错误提示

---

## 附录

### 参考资料
- DeepSeek API文档
- 语义相似度评估方法
- EasyChat项目结构

### 术语表
- **语义相似度**: 文本在语义层面的相关程度
- **系统提示词**: 指导AI进行特定任务的指令
- **批量评估**: 自动化处理多个测试用例

---

**文档版本**: v1.0  
**创建日期**: 2024-01-15  
**更新日期**: 2024-01-15  
**负责人**: 开发团队