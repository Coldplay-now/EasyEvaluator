#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
easyEval æ ¸å¿ƒè¯„ä¼°è„šæœ¬
å®ç°å¯¹è¯å®Œæˆç‡è¯„ä¼°çš„ä¸»è¦é€»è¾‘
"""

import json
import time
import subprocess
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm

# å¯¼å…¥é…ç½®
import sys
sys.path.append(str(Path(__file__).parent.parent))
from config.config import CONFIG

class EasyEvalCore:
    """easyEval æ ¸å¿ƒè¯„ä¼°ç±»"""
    
    def __init__(self):
        self.config = CONFIG
        self.setup_logging()
        self.results = []
        self.failed_cases = []
        self.start_time = None
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_config = self.config["logging"]
        logging.basicConfig(
            level=getattr(logging, log_config["level"]),
            format=log_config["format"],
            handlers=[
                logging.FileHandler(log_config["file"]),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_test_cases(self) -> List[Dict]:
        """åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
        test_file = self.config["test_cases_file"]
        try:
            with open(test_file, 'r', encoding='utf-8') as f:
                test_cases = json.load(f)
            self.logger.info(f"åŠ è½½äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            return test_cases
        except FileNotFoundError:
            self.logger.error(f"æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return []
        except json.JSONDecodeError as e:
            self.logger.error(f"æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            return []
            
    def run_single_test(self, test_case: Dict) -> Dict:
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        test_id = test_case.get("id", "unknown")
        prompt = test_case.get("prompt", "")
        expected_keywords = test_case.get("expected_keywords", [])
        category = test_case.get("category", "unknown")
        priority = test_case.get("priority", "medium")
        
        self.logger.info(f"æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹: {test_id} [{category}]")
        
        result = {
            "test_id": test_id,
            "prompt": prompt,
            "category": category,
            "priority": priority,
            "timestamp": datetime.now().isoformat(),
            "success": False,
            "response": "",
            "error": None,
            "execution_time": 0,
            "retry_count": 0,
            "details": {}
        }
        
        max_retries = self.config["evaluation"].get("max_retries", 3)
        start_time = time.time()
        
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    self.logger.info(f"é‡è¯•æµ‹è¯•ç”¨ä¾‹ {test_id} (ç¬¬ {attempt} æ¬¡)")
                    time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
                
                # æ‰§è¡Œ EasyChat
                response = self._execute_easychat(prompt)
                result["response"] = response
                result["execution_time"] = time.time() - start_time
                result["retry_count"] = attempt
                
                # è¯„ä¼°å“åº”è´¨é‡
                success = self._evaluate_response(response, expected_keywords)
                result["success"] = success
                
                # è®°å½•è¯¦ç»†ä¿¡æ¯
                keywords_found = self._check_keywords(response, expected_keywords)
                result["details"] = {
                    "response_length": len(response),
                    "keywords_found": keywords_found,
                    "keywords_count": len(keywords_found),
                    "expected_keywords_count": len(expected_keywords),
                    "has_response": len(response.strip()) > 0,
                    "response_preview": response[:100] + "..." if len(response) > 100 else response
                }
                
                # å¦‚æœæˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                if success:
                    break
                    
                # å¦‚æœä¸æˆåŠŸä½†æœ‰å“åº”ï¼Œä¹Ÿè·³å‡ºå¾ªç¯ï¼ˆé¿å…æ— æ„ä¹‰é‡è¯•ï¼‰
                if len(response.strip()) > 0:
                    break
                    
            except Exception as e:
                result["error"] = str(e)
                result["execution_time"] = time.time() - start_time
                result["retry_count"] = attempt
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè®°å½•é”™è¯¯å¹¶é€€å‡º
                if attempt == max_retries:
                    self.logger.error(f"æµ‹è¯•ç”¨ä¾‹ {test_id} æ‰§è¡Œå¤±è´¥ (å·²é‡è¯• {max_retries} æ¬¡): {e}")
                    break
                else:
                    self.logger.warning(f"æµ‹è¯•ç”¨ä¾‹ {test_id} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
            
        return result
        
    def _execute_easychat(self, prompt: str) -> str:
        """æ‰§è¡Œ EasyChat å¹¶è·å–å“åº”"""
        easychat_main = self.config["easychat_main"]
        timeout = self.config["evaluation"]["response_timeout"]
        
        # æ„å»ºå‘½ä»¤
        cmd = ["python", str(easychat_main)]
        
        try:
            # æ‰§è¡Œå‘½ä»¤å¹¶ä¼ å…¥æç¤º
            process = subprocess.Popen(
                cmd,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=self.config["easychat_root"]
            )
            
            # å‘é€æç¤ºå¹¶è·å–å“åº”
            stdout, stderr = process.communicate(
                input=f"{prompt}\nexit\n",
                timeout=timeout
            )
            
            if process.returncode != 0:
                raise Exception(f"EasyChat æ‰§è¡Œå¤±è´¥: {stderr}")
                
            return self._extract_response(stdout)
            
        except subprocess.TimeoutExpired:
            process.kill()
            raise Exception(f"EasyChat æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)")
        except Exception as e:
            raise Exception(f"æ‰§è¡Œ EasyChat æ—¶å‡ºé”™: {e}")
            
    def _extract_response(self, output: str) -> str:
        """ä» EasyChat è¾“å‡ºä¸­æå–å®é™…å“åº”"""
        lines = output.strip().split('\n')
        response_lines = []
        
        # ç®€å•çš„å“åº”æå–é€»è¾‘
        # è·³è¿‡ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·è¾“å…¥ï¼Œæå–AIå“åº”
        for line in lines:
            line = line.strip()
            if line and not line.startswith('>'):
                response_lines.append(line)
                
        return '\n'.join(response_lines)
        
    def _evaluate_response(self, response: str, expected_keywords: List[str]) -> bool:
        """è¯„ä¼°å“åº”è´¨é‡"""
        if not response or len(response.strip()) == 0:
            return False
            
        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        if expected_keywords:
            keywords_found = self._check_keywords(response, expected_keywords)
            return len(keywords_found) > 0
            
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå…³é”®è¯ï¼Œåªè¦æœ‰å“åº”å°±ç®—æˆåŠŸ
        return True
        
    def _check_keywords(self, response: str, keywords: List[str]) -> List[str]:
        """æ£€æŸ¥å“åº”ä¸­åŒ…å«çš„å…³é”®è¯"""
        response_lower = response.lower()
        found_keywords = []
        
        for keyword in keywords:
            if keyword.lower() in response_lower:
                found_keywords.append(keyword)
                
        return found_keywords
        
    def run_evaluation(self) -> Dict:
        """è¿è¡Œå®Œæ•´è¯„ä¼°"""
        self.start_time = time.time()
        self.logger.info("å¼€å§‹è¿è¡Œè¯„ä¼°")
        
        # åŠ è½½æµ‹è¯•ç”¨ä¾‹
        test_cases = self.load_test_cases()
        if not test_cases:
            return {"error": "æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹"}
            
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹...")
        
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
        results = []
        failed_cases = []
        
        with tqdm(total=len(test_cases), desc="æ‰§è¡Œæµ‹è¯•", unit="ä¸ª") as pbar:
            for i, test_case in enumerate(test_cases):
                pbar.set_description(f"æ‰§è¡Œæµ‹è¯• [{i+1}/{len(test_cases)}]: {test_case.get('id', 'unknown')}")
                
                result = self.run_single_test(test_case)
                results.append(result)
                
                if not result["success"]:
                    failed_cases.append({
                        "id": result["test_id"],
                        "reason": result.get("error", "å“åº”ä¸ç¬¦åˆé¢„æœŸ"),
                        "details": result.get("details", {})
                    })
                
                # æ›´æ–°è¿›åº¦æ¡çŠ¶æ€
                success_count = sum(1 for r in results if r["success"])
                pbar.set_postfix({
                    "æˆåŠŸ": success_count,
                    "å¤±è´¥": len(results) - success_count,
                    "å®Œæˆç‡": f"{success_count/len(results)*100:.1f}%" if results else "0%"
                })
                
                pbar.update(1)
                
                # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡å¿«æ‰§è¡Œ
                time.sleep(0.1)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats = self._calculate_statistics(results)
        total_time = time.time() - self.start_time
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "timestamp": datetime.now().isoformat(),
            "total_tests": len(results),
            "total_execution_time": total_time,
            "statistics": stats,
            "failed_cases": failed_cases,
            "results": results
        }
        
        # ä¿å­˜ç»“æœ
        self._save_results(report)
        
        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        print(f"\nâœ… è¯„ä¼°å®Œæˆï¼")
        print(f"ğŸ“Š å¯¹è¯å®Œæˆç‡: {stats['success_rate']:.2%}")
        print(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}ç§’")
        
        if failed_cases:
            print(f"âŒ å¤±è´¥ç”¨ä¾‹æ•°: {len(failed_cases)}")
            
        self.logger.info(f"è¯„ä¼°å®Œæˆï¼Œå¯¹è¯å®Œæˆç‡: {stats['success_rate']:.2%}")
        return report
        
    def _calculate_statistics(self, results: List[Dict]) -> Dict:
        """è®¡ç®—è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        total = len(results)
        successful = sum(1 for r in results if r["success"])
        failed = total - successful
        
        avg_time = sum(r["execution_time"] for r in results) / total if total > 0 else 0
        total_retries = sum(r.get("retry_count", 0) for r in results)
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for result in results:
            category = result.get("category", "unknown")
            if category not in category_stats:
                category_stats[category] = {"total": 0, "successful": 0, "failed": 0}
            
            category_stats[category]["total"] += 1
            if result["success"]:
                category_stats[category]["successful"] += 1
            else:
                category_stats[category]["failed"] += 1
        
        # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„æˆåŠŸç‡
        for category in category_stats:
            stats = category_stats[category]
            stats["success_rate"] = stats["successful"] / stats["total"] if stats["total"] > 0 else 0
        
        # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
        priority_stats = {}
        for result in results:
            priority = result.get("priority", "medium")
            if priority not in priority_stats:
                priority_stats[priority] = {"total": 0, "successful": 0, "failed": 0}
            
            priority_stats[priority]["total"] += 1
            if result["success"]:
                priority_stats[priority]["successful"] += 1
            else:
                priority_stats[priority]["failed"] += 1
        
        # è®¡ç®—æ¯ä¸ªä¼˜å…ˆçº§çš„æˆåŠŸç‡
        for priority in priority_stats:
            stats = priority_stats[priority]
            stats["success_rate"] = stats["successful"] / stats["total"] if stats["total"] > 0 else 0
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        execution_times = [r["execution_time"] for r in results if r["execution_time"] > 0]
        min_time = min(execution_times) if execution_times else 0
        max_time = max(execution_times) if execution_times else 0
        
        return {
            "total_tests": total,
            "successful_tests": successful,
            "failed_tests": failed,
            "success_rate": successful / total if total > 0 else 0,
            "average_execution_time": avg_time,
            "min_execution_time": min_time,
            "max_execution_time": max_time,
            "total_retries": total_retries,
            "threshold_met": (successful / total) >= self.config["evaluation"]["success_threshold"] if total > 0 else False,
            "category_breakdown": category_stats,
            "priority_breakdown": priority_stats
        }
        
    def _save_results(self, report: Dict):
        """ä¿å­˜è¯„ä¼°ç»“æœï¼ˆJSONå’Œæ–‡æœ¬æ ¼å¼ï¼‰"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š
        json_filename = f"eval_report_{timestamp}.json"
        json_filepath = self.config["results_dir"] / json_filename
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜æ–‡æœ¬æ ¼å¼æ‘˜è¦
        txt_filename = f"eval_summary_{timestamp}.txt"
        txt_filepath = self.config["results_dir"] / txt_filename
        
        self._generate_text_summary(report, txt_filepath)
        
        self.logger.info(f"è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°:")
        self.logger.info(f"  JSONæŠ¥å‘Š: {json_filepath}")
        self.logger.info(f"  æ–‡æœ¬æ‘˜è¦: {txt_filepath}")
        
        return json_filepath, txt_filepath
    
    def _generate_text_summary(self, report: Dict, filepath: Path):
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„è¯„ä¼°æ‘˜è¦"""
        stats = report["statistics"]
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("easyEval å¯¹è¯å®Œæˆç‡è¯„ä¼°æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            # åŸºæœ¬ä¿¡æ¯
            f.write(f"è¯„ä¼°æ—¶é—´: {report['timestamp']}\n")
            f.write(f"æ€»æ‰§è¡Œæ—¶é—´: {report.get('total_execution_time', 0):.2f}ç§’\n\n")
            
            # æ€»ä½“ç»Ÿè®¡
            f.write("ğŸ“Š æ€»ä½“ç»Ÿè®¡\n")
            f.write("-" * 30 + "\n")
            f.write(f"æ€»æµ‹è¯•æ•°: {stats['total_tests']}\n")
            f.write(f"æˆåŠŸæ•°: {stats['successful_tests']}\n")
            f.write(f"å¤±è´¥æ•°: {stats['failed_tests']}\n")
            f.write(f"å¯¹è¯å®Œæˆç‡: {stats['success_rate']:.2%}\n")
            f.write(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['average_execution_time']:.2f}ç§’\n")
            f.write(f"æœ€çŸ­æ‰§è¡Œæ—¶é—´: {stats['min_execution_time']:.2f}ç§’\n")
            f.write(f"æœ€é•¿æ‰§è¡Œæ—¶é—´: {stats['max_execution_time']:.2f}ç§’\n")
            f.write(f"æ€»é‡è¯•æ¬¡æ•°: {stats['total_retries']}\n")
            f.write(f"æ˜¯å¦è¾¾åˆ°é˜ˆå€¼: {'âœ… æ˜¯' if stats['threshold_met'] else 'âŒ å¦'}\n\n")
            
            # æŒ‰åˆ†ç±»ç»Ÿè®¡
            if "category_breakdown" in stats:
                f.write("ğŸ“‹ æŒ‰åˆ†ç±»ç»Ÿè®¡\n")
                f.write("-" * 30 + "\n")
                for category, cat_stats in stats["category_breakdown"].items():
                    f.write(f"{category}:\n")
                    f.write(f"  æ€»æ•°: {cat_stats['total']}\n")
                    f.write(f"  æˆåŠŸ: {cat_stats['successful']}\n")
                    f.write(f"  å¤±è´¥: {cat_stats['failed']}\n")
                    f.write(f"  æˆåŠŸç‡: {cat_stats['success_rate']:.2%}\n\n")
            
            # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
            if "priority_breakdown" in stats:
                f.write("ğŸ¯ æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡\n")
                f.write("-" * 30 + "\n")
                for priority, pri_stats in stats["priority_breakdown"].items():
                    f.write(f"{priority}:\n")
                    f.write(f"  æ€»æ•°: {pri_stats['total']}\n")
                    f.write(f"  æˆåŠŸ: {pri_stats['successful']}\n")
                    f.write(f"  å¤±è´¥: {pri_stats['failed']}\n")
                    f.write(f"  æˆåŠŸç‡: {pri_stats['success_rate']:.2%}\n\n")
            
            # å¤±è´¥ç”¨ä¾‹è¯¦æƒ…
            if "failed_cases" in report and report["failed_cases"]:
                f.write("âŒ å¤±è´¥ç”¨ä¾‹è¯¦æƒ…\n")
                f.write("-" * 30 + "\n")
                for i, failed_case in enumerate(report["failed_cases"], 1):
                    f.write(f"{i}. {failed_case['id']}\n")
                    f.write(f"   åŸå› : {failed_case['reason']}\n")
                    if "details" in failed_case and failed_case["details"]:
                        f.write(f"   è¯¦æƒ…: {failed_case['details']}\n")
                    f.write("\n")
            
            f.write("=" * 60 + "\n")
            f.write("æŠ¥å‘Šç”Ÿæˆå®Œæˆ\n")
        
def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– easyEval - EasyChat å¯¹è¯å®Œæˆç‡è¯„ä¼°å·¥å…·")
    print("=" * 50)
    
    evaluator = EasyEvalCore()
    report = evaluator.run_evaluation()
    
    if "error" in report:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {report['error']}")
        return 1
        
    stats = report["statistics"]
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š === è¯¦ç»†è¯„ä¼°ç»“æœ === ğŸ“Š")
    print(f"æ€»æµ‹è¯•æ•°: {stats['total_tests']}")
    print(f"æˆåŠŸæ•°: {stats['successful_tests']} âœ…")
    print(f"å¤±è´¥æ•°: {stats['failed_tests']} âŒ")
    print(f"å¯¹è¯å®Œæˆç‡: {stats['success_rate']:.2%}")
    print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['average_execution_time']:.2f}ç§’")
    print(f"æ‰§è¡Œæ—¶é—´èŒƒå›´: {stats['min_execution_time']:.2f}s - {stats['max_execution_time']:.2f}s")
    print(f"æ€»é‡è¯•æ¬¡æ•°: {stats['total_retries']}")
    print(f"æ˜¯å¦è¾¾åˆ°é˜ˆå€¼: {'âœ… æ˜¯' if stats['threshold_met'] else 'âŒ å¦'}")
    
    # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
    if "category_breakdown" in stats and stats["category_breakdown"]:
        print(f"\nğŸ“‹ æŒ‰åˆ†ç±»ç»Ÿè®¡:")
        for category, cat_stats in stats["category_breakdown"].items():
            print(f"  {category}: {cat_stats['successful']}/{cat_stats['total']} ({cat_stats['success_rate']:.1%})")
    
    # æ˜¾ç¤ºä¼˜å…ˆçº§ç»Ÿè®¡
    if "priority_breakdown" in stats and stats["priority_breakdown"]:
        print(f"\nğŸ¯ æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡:")
        for priority, pri_stats in stats["priority_breakdown"].items():
            print(f"  {priority}: {pri_stats['successful']}/{pri_stats['total']} ({pri_stats['success_rate']:.1%})")
    
    # æ˜¾ç¤ºå¤±è´¥ç”¨ä¾‹æ‘˜è¦
    if "failed_cases" in report and report["failed_cases"]:
        print(f"\nâŒ å¤±è´¥ç”¨ä¾‹æ‘˜è¦ (å‰5ä¸ª):")
        for i, failed_case in enumerate(report["failed_cases"][:5], 1):
            print(f"  {i}. {failed_case['id']}: {failed_case['reason']}")
        
        if len(report["failed_cases"]) > 5:
            print(f"  ... è¿˜æœ‰ {len(report['failed_cases']) - 5} ä¸ªå¤±è´¥ç”¨ä¾‹")
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° results/ ç›®å½•")
    print("=" * 50)
    
    return 0
    
if __name__ == "__main__":
    exit(main())